---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='Education'></span>
# ğŸ“ Education
<style>
  .timeline-container {
    display: flex;
    flex-direction: column;
    width: 100%;
    max-width: 900px;
    margin: 0 auto;
    font-family: Arial, sans-serif;
  }
  .timeline-item {
    display: flex;
    align-items: center;
    margin: 8px 0;
  }
  .time-column {
    flex: 0 0 150px;
    text-align: center;
  }
  .logo-column {
    flex: 0 0 40px;
    text-align: center;
  }
  .org-column {
    flex: 0 0 300px;
    text-align: center;
    padding: 0 15px;
  }
  .xy-column {
    flex: 0 0 160px;
    text-align: center;
    padding: 0 15px;
  }
  .degree-column {
    flex: 0 0 120px;
    text-align: center;
    padding-left: 15px;
  }
</style>

<div class="timeline-container">
  <div class="timeline-item">
    <span class="time-column">2020.09 - 2025.06</span>
    <span class="logo-column">
      <a href="https://www.ustb.edu.cn/" target="_blank">
        <img src="/images/logo/åŒ—ç§‘_logo.jpeg" alt="åŒ—äº¬ç§‘æŠ€å¤§å­¦" width="20">
      </a>
    </span>
    <span class="org-column">åŒ—äº¬ç§‘æŠ€å¤§å­¦</span>
    <span class="xy-column">è®¡ç®—æœºä¸é€šä¿¡å·¥ç¨‹å­¦é™¢</span>
    <span class="xy-column">è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯</span>
    <span class="degree-column">åšå£«</span>
  </div>

  <div class="timeline-item">
    <span class="time-column">2019.07 - 2020.09</span>
    <span class="logo-column">
      <a href="https://www.suning.com/" target="_blank">
        <img src="/images/logo/è‹å®_logo.jpeg" alt="è‹å®ç§‘æŠ€" width="20">
      </a>
    </span>
    <span class="org-column">è‹å®ç§‘æŠ€é›†å›¢/æµ·ç ”è‡ªåŠ¨åŒ–ç§‘æŠ€æœ‰é™å…¬å¸</span>
    <span class="xy-column">å›¾åƒå®éªŒå®¤</span>
    <span class="xy-column">-</span>
    <span class="degree-column">å›¾åƒç®—æ³•å·¥ç¨‹å¸ˆ</span>
  </div>

  <div class="timeline-item">
    <span class="time-column">2017.09 - 2019.06</span>
    <span class="logo-column">
      <a href="https://www.bjtu.edu.cn/" target="_blank">
        <img src="/images/logo/åŒ—äº¤_logo.jpeg" alt="åŒ—äº¬äº¤é€šå¤§å­¦" width="20">
      </a>
    </span>
    <span class="org-column">åŒ—äº¬äº¤é€šå¤§å­¦</span>
    <span class="xy-column">ç”µå­ä¿¡æ¯å·¥ç¨‹å­¦é™¢</span>
    <span class="xy-column">ç”µå­ä¸é€šä¿¡å·¥ç¨‹</span>
    <span class="degree-column">ç¡•å£«</span>
  </div>

  <div class="timeline-item">
    <span class="time-column">2013.09 - 2017.06</span>
    <span class="logo-column">
      <a href="https://www.nuc.edu.cn/" target="_blank">
        <img src="/images/logo/ä¸­åŒ—_logo.jpeg" alt="ä¸­åŒ—å¤§å­¦" width="20">
      </a>
    </span>
    <span class="org-column">ä¸­åŒ—å¤§å­¦</span>
    <span class="xy-column">ä¿¡æ¯ä¸é€šä¿¡å·¥ç¨‹å­¦é™¢</span>
    <span class="xy-column">å…‰ç”µä¿¡æ¯ç§‘å­¦ä¸æŠ€æœ¯</span>
    <span class="degree-column">å­¦å£«</span>
  </div>
</div>


<span class='anchor' id='Research Direction'></span>
# âœ¨ Research Direction
ç ”ç©¶æ–¹å‘:
- æ·±åº¦å­¦ä¹ 
- è®¡ç®—æœºè§†è§‰
- å°æ ·æœ¬å­¦ä¹ 

<span class='anchor' id='Selected Publications'></span>
# ğŸ“ Selected Publications

### Papers
---
PS: Authors with equal contribution are marked by \*.

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024</div><img src='thumbs/NeurIPS2024_01.png' alt="sym"></div></div>
<div class='paper-box-text' markdown="1">

**Yi Ma**, Jianye Hao, Xiaohan Hu, Yan Zheng,  Chenjun Xiao. <br>
*Iteratively Refined Behavior Regularization for Offline Reinforcement Learning*. <br>
NeurIPS 2024. (`CCF A`)  <br>
[[link]]()

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024</div><img src='thumbs/NeurIPS2024_02.png' alt="sym"></div></div>
<div class='paper-box-text' markdown="1">

Jiashun Liu, Jianye Hao, Xiaotian Hao, **Yi Ma**,  Yan Zheng, Yujing Hu, Tangjie Lv. <br>
*Unlock the Intermittent Control Ability of Model Free Reinforcement Learning*. <br>
NeurIPS 2024. (`CCF A`)  <br>
[[link]]()

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024 </div><img src='thumbs/NeurIPS2024_03.png' alt="sym"></div></div>
<div class='paper-box-text' markdown="1">

Zibin Dong, Yifu Yuan, Jianye Hao, Fei Ni, **Yi Ma**, Pengyi Li, Yan Zheng. <br>
*CleanDiffuser: An Easy-to-use Modularized Library for Diffusion Models in Decision Making*. <br>
NeurIPS 2024 Datasets and Benchmarks Track. (`CCF A`)  <br>
[[link]]()

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2024</div><img src='thumbs/ICML2024_01.png' alt="sym"></div></div>
<div class='paper-box-text' markdown="1">

**Yi Ma**, Jianye Hao, Hebin Liang,  Chenjun Xiao. <br>
*Rethinking Decision Transformer via Hierarchical Reinforcement Learning*. <br>
ICML 2024. (`CCF A`)  <br>
[[link]](https://arxiv.org/abs/2311.00267)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2024</div><img src='thumbs/ICML2024_02.png' alt="sym"></div></div>
<div class='paper-box-text' markdown="1">

Jiashun Liu, Jianye HAO, **Yi Ma**, Shuyin Xia. <br>
*Imagine Big from Small: Unlock the Cognitive Generalization of Deep Reinforcement Learning from Simple Scenarios*. <br>
ICML 2024. (`CCF A`)  <br>
[[link]]()

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCAI 2024</div><img src='thumbs/IJCAI2024.png' alt="sym"></div></div>
<div class='paper-box-text' markdown="1">

Kai Zhao, Jianye Hao, **Yi Ma**, Jinyi Liu, Yan Zheng, Zhaopeng Meng. <br>
*ENOTO: Improving Offline-to-Online Reinforcement Learning with Q-Ensembles*. <br>
IJCAI 2024. (`CCF A`)  <br>
[[link]]()

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2024</div><img src='thumbs/ICLR2024.jpg' alt="sym"></div></div>
<div class='paper-box-text' markdown="1">
Yifu Yuan, Jianye Hao, **Yi Ma**, Zibin Dong, Hebin Liang, Jinyi Liu, Zhixin Feng, Kai Zhao, Yan Zheng. <br>
*Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedback*. <br>
ICLR 2024. (`Top AI Conference`)  <br>
[[link]](https://openreview.net/forum?id=WesY0H9ghM&referrer=%5Bthe%20profile%20of%20Jinyi%20Liu%5D(%2Fprofile%3Fid%3D~Jinyi_Liu1))

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2023</div><img src='thumbs/NeurIPS2023.png' alt="sym"></div></div>
<div class='paper-box-text' markdown="1">

**Yi Ma**, Hongyao Tang, Dong Li, Zhaopeng Meng. <br>
*Reining Generalization in Offline Reinforcement Learning via Representation Distinction*. <br>
NeurIPS 2023. (`CCF A`)  <br>
[[link]](https://proceedings.neurips.cc/paper_files/paper/2023/hash/802a4350ca4fced76b13b8b320af1543-Abstract-Conference.html)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CIKM 2023</div><img src='thumbs/CIKM2023.png' alt="sym"></div></div>
<div class='paper-box-text' markdown="1">

Hebin Liang, Zibin Dong, **Yi Ma**, Xiaotian Hao, Yan Zheng, Jianye Hao. <br>
*A Hierarchical Imitation Learning-based Decision Framework for Autonomous Driving*. <br>
CIKM 2023. (`CCF B`)  <br>
[[link]](https://dl.acm.org/doi/10.1145/3583780.3615454) 


</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2023</div><img src='thumbs/AAAI2023.png' alt="sym"></div></div>
<div class='paper-box-text' markdown="1">


Hebin Liang\* , **Yi Ma\***, Zilin Cao, Tianyang Liu, Fei Ni, Zhigang Li, Jianye Hao. <br>
*SplitNet: A Reinforcement Learning based Sequence Splitting Method for the MinMax Multiple Travelling Salesman Problem*. <br>
AAAI 2023. (`CCF A`)  <br>
[[link]](https://ojs.aaai.org/index.php/AAAI/article/view/26049) 


</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CAAI AIR 2023</div><img src='thumbs/CAAI2023.png' alt="sym"></div></div>
<div class='paper-box-text' markdown="1">


**Yi Ma**, Chao Wang, Chen Chen, Jinyi Liu, Zhaopeng Meng, Yan Zheng, Jianye Hao. <br>
*OSCAR: OOD State Conservative Offline Reinforcement Learning for S equential Decision Making*. <br>
CAAI Aritificial Intelligence Research 2023.  <br>
[[link]](https://www.sciopen.com/article/10.26599/AIR.2023.9150020) 


</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCAI 2022</div><img src='thumbs/IJCAI2022.png' alt="sym"></div></div>
<div class='paper-box-text' markdown="1">


Tong Sang, Hongyao Tang, **Yi Ma**, Jianye Hao, Yan Zheng, Zhaopeng Meng, Boyan Li, Zhen Wang. <br>
*PAnDR: Fast Adaptation to New Environments from Offline Experiences via Decoupling Policy and Environment Representations*. <br>
IJCAI 2022. (`CCF A`)  <br>
[[link]](https://www.ijcai.org/proceedings/2022/0474.pdf) 


</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2021</div><img src='thumbs/NeurIPS2021.png' alt="sym" ></div></div>
<div class='paper-box-text' markdown="1">


**Yi Ma**, Xiaotian Hao\*, Jianye Hao, Jiawen Lu, Xing Liu, Tong Xialiang, Mingxuan Yuan, Zhigang Li, Jie Tang, Zhaopeng Meng.<br>
*A hierarchical reinforcement learning based optimization framework for large scale dynamic pickup and delivery problems*. <br>
NeurIPS 2021. (`CCF A`)  <br>
[[link]](https://proceedings.neurips.cc/paper/2021/file/c6a01432c8138d46ba39957a8250e027-Paper.pdf) 


</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">KDD 2021</div><img src='thumbs/KDD2021.png' alt="sym"></div></div>
<div class='paper-box-text' markdown="1">


Fei Ni, Jianye Hao, Jiawen Lu, Xialiang Tong, Mingxuan Yuan, Jiahui Duan, **Yi Ma**, Kun He <br>
*A Multi-Graph Attributed Reinforcement Learning based Optimization Algorithm for Large-scale Hybrid Flow Shop Scheduling Problem*. <br>
KDD 2021. (`CCF A`)  <br>
[[link]](https://dl.acm.org/doi/abs/10.1145/3447548.3467135) 


</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2020</div><img src='thumbs/ICML2020.png' alt="sym"></div></div>
<div class='paper-box-text' markdown="1">


Xiaotian Hao\*, Zhaoqing Peng\*, **Yi Ma\***, Guan Wang, Junqi Jin, Jianye Hao, Shan Chen, Rongquan Bai, Mingzhou Xie, Miao Xu, Zhenzhe Zheng, Chuan Yu, Han Li, Jian Xu, Kun Gai. <br>
*Dynamic Knapsack Optimization Towards Efficient Multi-Channel Sequential Advertising*. <br>
ICML 2020. (`CCF A`)  <br>
[[link]](https://proceedings.mlr.press/v119/hao20b/hao20b.pdf) 


</div>
</div>




### Patents
---
- CN113850414B. Method for Logistics Scheduling Planning Based on Graph Neural Networks and Reinforcement Learning. (First Inventor, Authorized)
- CN114130034B. Multi Agent Game AI Design Method Based on Attention Mechanism and Reinforcement Learning. (Fifth Inventor, Authorized)
- CN113947348A. A Method and Device for Order Allocation. (Second Inventor, Under Review)
- CN113869489A. Complex Game AI Design Method Based on Hierarchical Deep Reinforcement Learning. (Third Inventor, Authorized)
- CN113869488A. Reinforcement Learning Method for Game AI Agents in Continuous Discrete Mixed Decision Environments. (Third Inventor, Authorized)
- CN114169421A. Cooperative Exploration Method in Sparse Reward Environments for Multi Agent Systems Based on Intrinsic Motivation. (Fourth Inventor, Under Review)
- CN114139681A. Meta Reinforcement Learning Method Based on Contrastive Learning and Mutual Information. (Fourth Inventor, Under Review)




<span class='anchor' id='Competitions and Honors'></span>

# ğŸ… Competitions and Honors
- *2022.12*, NeurIPS 2022 SMARTS Autonomous Driving Competition. `First Prize` in both tracks. [[link]](https://smarts-project.github.io/archive/2022_nips_driving_smarts/competition/)  
- *2021.06*, Huawei 2012 Central Research Institute Innovation Pioneer. `President's Award Second Prize`.
- *2017.12*,  Intel Cup National College Students Software Innovation Competition `National Finals Third prize`  

<span class='anchor' id='Invited Talks'></span>

# ğŸ›ï¸ Invited Talks
- *2024.7*, Transformer-based Models in Decision Making. @NJU
- *2023.12*, Reining Generalization in Offline Reinforcement Learning via Representation Distinction. @DAI 2023
- 2022.11, The Difficulty of Passive Learning in Deep Reinforcement Learning. @Huawei, Chaspark 
- *2022.01*, A hierarchical reinforcement learning based optimization framework for large scale dynamic
pickup and delivery problems @RLChina


<span class='anchor' id='Internships'></span>

# ğŸ’» Internships
- *2024.01-2024.07*, Qiyuan Lab, AI Foundation Team. Supervised by Chen Chen.
- *2020.11-2023.11*, Huawei Noahâ€™s Ark Lab, Decision and Reasoning Team. Supervised by Chenjun Xiao, Dong Li, Chen Chen and Chao Wang.
- *2020.04-2020.10*, Huawei Noahâ€™s Ark Lab, Enterprise Intelligence Team. Supervised by  Jiawen Lu.
- *2019.07-2019.12*, Alibaba, Alimama Target Advertising Team.  Supervised by Junqi Jin.

<span class='anchor' id='Academic Service'></span>
# ğŸŒ Academic Service

- Reviewer for Conferences: ICML, ICLR, NeurIPS, AAAI, IJCAI, AAMAS, DAI, CIKM.

- Student Contactor of RLChina.

  
