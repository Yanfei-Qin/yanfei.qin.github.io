---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hey, I'm Yi Ma, a 4th year PhD candidate of <a href="http://cic.tju.edu.cn/">College of Intelligence and Computing</a> in <a href="http://www.tju.edu.cn/">Tianjin University</a>. I'm a member of Professor <a href="http://www.icdai.org/jianye.html">Jianye Hao</a>'s <a href="http://www.icdai.org/">research group</a>. I have an research interest in offline reinforcement learning and application of RL. </p>
    <p>Besides, I'm a huge fan of basketball, snowboarding and orienteering. I have published more than 20 papers in top AI conferences. <a href='https://scholar.google.com/citations?user=TdVWzqgAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=ÂºïÁî®"></a>„ÄÇ

I'm interested in:
- Reinforcement Learning
- Offline Reinforcement Learning
- Application of Deep Reinforcement Learning

  


<span class='anchor' id='-xl'></span>

# üéì Education
- *2020.09 - 2024.06*, <a href="https://www.tju.edu.cn/"><img class="svg" src="/images/tju_logo.jpg" width="20pt"></a> Tianjin University, PhD 
- *2018.09 - 2020.06*, <a href="https://www.tju.edu.cn/"><img class="svg" src="/images/tju_logo.jpg" width="20pt"></a>  Tianjin University, Master 
- *2014.09 - 2018.06*, <a href="https://www.tju.edu.cn/"><img class="svg" src="/images/tju_logo.jpg" width="20pt"></a>  Tianjin University, Bachelor 
 
<span class='anchor' id='-lwzl'></span>

# üìù Selected Publications

### Papers
---

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCAI 2024</div><img src='thumbs/IJCAI2024.png' alt="sym" width="100%" height="100%"></div></div>
<div class='paper-box-text' markdown="1">

Kai Zhao, Jianye Hao, **Yi Ma**, Jinyi Liu, Yan Zheng, Zhaopeng Meng. <br>
*ENOTO: Improving Offline-to-Online Reinforcement Learning with Q-Ensembles*. <br>
IJCAI 2024. (`CCF A`)  <br>
[[link]]()

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2023</div><img src='thumbs/ICLR2024.jpg' alt="sym" width="100%" height="100%"></div></div>
<div class='paper-box-text' markdown="1">
Yifu Yuan, Jianye Hao, **Yi Ma**, Zibin Dong, Hebin Liang, Jinyi Liu, Zhixin Feng, Kai Zhao, Yan Zheng. <br>
*Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedback*. <br>
ICLR 2024. (`Top AI Conference`)  <br>
[[link]](https://openreview.net/forum?id=WesY0H9ghM&referrer=%5Bthe%20profile%20of%20Jinyi%20Liu%5D(%2Fprofile%3Fid%3D~Jinyi_Liu1))

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2023</div><img src='thumbs/NeurIPS2023.png' alt="sym" width="100%" height="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Yi Ma**, Hongyao Tang, Dong Li, Zhaopeng Meng. <br>
*Reining Generalization in Offline Reinforcement Learning via Representation Distinction*. <br>
NeurIPS 2023. (`CCF A`)  <br>
[[link]](https://proceedings.neurips.cc/paper_files/paper/2023/hash/802a4350ca4fced76b13b8b320af1543-Abstract-Conference.html)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CIKM 2023</div><img src='thumbs/CIKM2023.png' alt="sym" width="100%" height="100%"></div></div>
<div class='paper-box-text' markdown="1">

Hebin Liang, Zibin Dong, **Yi Ma**, Xiaotian Hao, Yan Zheng, Jianye Hao. <br>
*A Hierarchical Imitation Learning-based Decision Framework for Autonomous Driving*. <br>
CIKM 2023. (`CCF B`)  <br>
[[link]](https://dl.acm.org/doi/10.1145/3583780.3615454) 


</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2023</div><img src='thumbs/AAAI2023.png' alt="sym" width="100%" height="100%"></div></div>
<div class='paper-box-text' markdown="1">


Hebin Liang\* , **Yi Ma\***, Zilin Cao, Tianyang Liu, Fei Ni, Zhigang Li, Jianye Hao. <br>
*SplitNet: A Reinforcement Learning based Sequence Splitting Method for the MinMax Multiple Travelling Salesman Problem*. <br>
AAAI 2023. (`CCF A`)  <br>
[[link]](https://ojs.aaai.org/index.php/AAAI/article/view/26049) 


</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CAAI AIR 2023</div><img src='thumbs/CAAI2023.png' alt="sym" width="100%" height="100%"></div></div>
<div class='paper-box-text' markdown="1">


**Yi Ma**, Chao Wang, Chen Chen, Jinyi Liu, Zhaopeng Meng, Yan Zheng, Jianye Hao. <br>
*OSCAR: OOD State Conservative Offline Reinforcement Learning for S equential Decision Making*. <br>
CAAI Aritificial Intelligence Research 2023.  <br>
[[link]](https://www.sciopen.com/article/10.26599/AIR.2023.9150020) 


</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCAI 2022</div><img src='thumbs/IJCAI2022.png' alt="sym" width="100%" height="100%"></div></div>
<div class='paper-box-text' markdown="1">


Tong Sang, Hongyao Tang, **Yi Ma**, Jianye Hao, Yan Zheng, Zhaopeng Meng, Boyan Li, Zhen Wang. <br>
*PAnDR: Fast Adaptation to New Environments from Offline Experiences via Decoupling Policy and Environment Representations*. <br>
IJCAI 2022. (`CCF A`)  <br>
[[link]](https://www.ijcai.org/proceedings/2022/0474.pdf) 


</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2021</div><img src='thumbs/NeurIPS2021.png' alt="sym" width="100%" height="100%"></div></div>
<div class='paper-box-text' markdown="1">


**Yi Ma**, Xiaotian Hao\*, Jianye Hao, Jiawen Lu, Xing Liu, Tong Xialiang, Mingxuan Yuan, Zhigang Li, Jie Tang, Zhaopeng Meng.<br>
*A hierarchical reinforcement learning based optimization framework for large scale dynamic pickup and delivery problems*. <br>
NeurIPS 2021. (`CCF A`)  <br>
[[link]](https://proceedings.neurips.cc/paper/2021/file/c6a01432c8138d46ba39957a8250e027-Paper.pdf) 


</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">KDD 2021</div><img src='thumbs/KDD2021.png' alt="sym" width="100%" height="100%"></div></div>
<div class='paper-box-text' markdown="1">


Fei Ni, Jianye Hao, Jiawen Lu, Xialiang Tong, Mingxuan Yuan, Jiahui Duan, **Yi Ma**, Kun He <br>
*A Multi-Graph Attributed Reinforcement Learning based Optimization Algorithm for Large-scale Hybrid Flow Shop Scheduling Problem*. <br>
KDD 2021. (`CCF A`)  <br>
[[link]](https://dl.acm.org/doi/abs/10.1145/3447548.3467135) 


</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2020</div><img src='thumbs/ICML2020.png' alt="sym" width="100%" height="100%"></div></div>
<div class='paper-box-text' markdown="1">


Xiaotian Hao\*, Zhaoqing Peng\*, **Yi Ma\***, Guan Wang, Junqi Jin, Jianye Hao, Shan Chen, Rongquan Bai, Mingzhou Xie, Miao Xu, Zhenzhe Zheng, Chuan Yu, Han Li, Jian Xu, Kun Gai. <br>
*Dynamic Knapsack Optimization Towards Efficient Multi-Channel Sequential Advertising*. <br>
ICML 2020. (`CCF A`)  <br>
[[link]](https://proceedings.mlr.press/v119/hao20b/hao20b.pdf) 


</div>
</div>




### Patents
---
- CN113850414B. Method for Logistics Scheduling Planning Based on Graph Neural Networks and Reinforcement Learning. (First Inventor, Authorized)
- CN114130034B. Multi Agent Game AI Design Method Based on Attention Mechanism and Reinforcement Learning. (Fifth Inventor, Authorized)
- CN113947348A. A Method and Device for Order Allocation. (Second Inventor, Under Review)
- CN113869489A. Complex Game AI Design Method Based on Hierarchical Deep Reinforcement Learning. (Third Inventor, Under Review)
- CN113869488A. Reinforcement Learning Method for Game AI Agents in Continuous Discrete Mixed Decision Environments. (Third Inventor, Under Review)
- CN114169421A. Cooperative Exploration Method in Sparse Reward Environments for Multi Agent Systems Based on Intrinsic Motivation. (Fourth Inventor, Under Review)
- CN114139681A. Meta Reinforcement Learning Method Based on Contrastive Learning and Mutual Information. (Fourth Inventor, Under Review)




<span class='anchor' id='-ryjx'></span>

# üèÖ Competitions and Honors
- *2022.12*, NeurIPS 2022 SMARTS Autonomous Driving Competition. `First Prize` in both tracks. [[link]](https://smarts-project.github.io/archive/2022_nips_driving_smarts/competition/)  
- *2021.06*, Huawei 2012 Central Research Institute Innovation Pioneer. `President's Award Second Prize`.
- *2017.12*,  Intel Cup National College Students Software Innovation Competition `National Finals Third prize`  

<span class='anchor' id='-xshy'></span>

# üèõÔ∏è Invited Talks
- *2023.12*, Reining Generalization in Offline Reinforcement Learning via Representation Distinction. @DAI 2023
- *2022.01*, A hierarchical reinforcement learning based optimization framework for large scale dynamic
pickup and delivery problems @RLChina


<span class='anchor' id='-gzsx'></span>

# üíª Internships
- *2020.11-2023.11*, Huawei Noah‚Äôs Ark Lab, Decision and Reasoning Team.
- *2020.04-2020.10*, Huawei Noah‚Äôs Ark Lab, Enterprise Intelligence Team.
- *2019.07-2019.12*, Alibaba, Alimama Target Advertising Team.
